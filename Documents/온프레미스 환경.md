실시간 데이터
1. 외부서버에서 api 형식으로 kafka 로 데이터를 가져옴 
2. 가져온 데이터를 spark 를 사용하여 데이터 처리함.
3. 처리한 데이터를 redis 에 저장하고 apache iceberg 를 사용하여 hdfs 에 저장함.
4. redis 에 저장한 데이터를 tomcat 을 사용해서 사용자에게 웹으로 보여줌

메타데이터
1. 외부서버에서 txt 형식으로 메타데이터를 로컬 저장소에 저장함.
2. flume 을 사용해서 txt 를 hdfs 에 적재함
3. hdfs 에 적재된 txt 데이터는 위의 실시간 데이터와 함께 spark streaming 으로 데이터 처리함.
4. 처리한 데이터는 apache iceberg 를 사용해서 hdfs 에 저장됨

웹서버
1. 웹서버는 spring 과 mybatis 를 사용해서 웹서버와 api 서버가 두개 있음.
2. 쿠버네티스를 사용해서 어플리케이션 의존성 관리

모니터링
1. elasticsearch 를 포함한 elk 스택 활용

오류 처리 및 복구 메커니즘
1. YARN 과 zookeeper 를 사용한 ha 환경 구축
